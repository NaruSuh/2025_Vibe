import streamlit as st
import requests
import os
from dotenv import load_dotenv
from datetime import datetime
import openai
from professors_database import (
    search_professors_by_keyword, 
    get_research_areas, 
    get_universities, 
    get_professors_by_university,
    generate_video_search_keywords,
    APA_PROFESSORS_DATABASE
)

load_dotenv()

st.set_page_config(
    page_title="ÏûÑÏÉÅÏã¨Î¶¨Ìïô ÎèôÏòÅÏÉÅ Ï∂îÏ≤ú",
    page_icon="üß†",
    layout="wide"
)

def get_professor_prompt_template(professor_data):
    """ÍµêÏàòÎãòÎ≥Ñ ÎßûÏ∂§Ìòï ÌîÑÎ°¨ÌîÑÌä∏ ÌÖúÌîåÎ¶ø"""
    prof = professor_data["professor"]
    university = professor_data["university"]
    
    prompt = f"""
ÎãπÏã†ÏùÄ {university}Ïùò {prof['name']} ÍµêÏàòÎãò Ïó∞Íµ¨Ïã§ ÏßÄÏõêÏùÑ ÎèïÎäî Ï†ÑÎ¨∏ ÏÉÅÎã¥ÏÇ¨ÏûÖÎãàÎã§.

üìã ÍµêÏàòÎãò Ï†ïÎ≥¥:
- Ïù¥Î¶Ñ: {prof['name']}
- ÏÜåÏÜç: {university} ({professor_data.get('location', '')})
- Ïó∞Íµ¨Ïã§: {prof.get('lab', 'Ï†ïÎ≥¥ ÏóÜÏùå')}
- Ï†ÑÎ¨∏ Î∂ÑÏïº: {', '.join(prof.get('research_areas', []))}
- Ïó∞Íµ¨ ÌÇ§ÏõåÎìú: {prof.get('research_keywords', '')}

üéØ Ïó≠Ìï†:
1. Ïù¥ ÍµêÏàòÎãò Ïó∞Íµ¨Ïã§ ÏßÄÏõêÏóê Í¥ÄÌïú Î™®Îì† ÏßàÎ¨∏Ïóê ÎãµÎ≥Ä
2. Ïó∞Íµ¨ Î∂ÑÏïº ÏÑ§Î™Ö Î∞è ÏµúÏã† ÎèôÌñ• Ï†úÍ≥µ  
3. ÏßÄÏõêÏÑú ÏûëÏÑ± Ï°∞Ïñ∏ Î∞è Î©¥Ï†ë Ï§ÄÎπÑ ÎèÑÏõÄ
4. Í¥ÄÎ†® ÎÖºÎ¨∏, Ïó∞Íµ¨ Î∞©Ìñ•ÏÑ± Ï∂îÏ≤ú
5. ÎåÄÌïôÏõê ÏÉùÌôú Î∞è Ïª§Î¶¨Ïñ¥ Ï°∞Ïñ∏

üí° ÏùëÎãµ Ïä§ÌÉÄÏùº:
- Îî∞ÎúªÌïòÍ≥† Í≤©Î†§Ï†ÅÏù∏ ÌÜ§
- Íµ¨Ï≤¥Ï†ÅÏù¥Í≥† Ïã§Ïö©Ï†ÅÏù∏ Ï°∞Ïñ∏
- ÌïúÍµ≠Ïñ¥Î°ú ÎãµÎ≥Ä (ÌïÑÏöîÏãú ÏòÅÏñ¥ Ï†ÑÎ¨∏Ïö©Ïñ¥ Î≥ëÍ∏∞)
- Î∂àÌôïÏã§Ìïú Ï†ïÎ≥¥Îäî Ï∂îÍ∞Ä ÌôïÏù∏ÏùÑ Í∂åÏú†

Ïñ¥Îñ§ ÎèÑÏõÄÏù¥ ÌïÑÏöîÌïòÏã†Í∞ÄÏöî?
"""
    return prompt

def get_question_templates():
    """ÏßàÎ¨∏ Í≤¨Î≥∏ Î∞è Ï∂îÏ≤ú ÏßàÎ¨∏Îì§"""
    return {
        "üî¨ Ïó∞Íµ¨ Î∂ÑÏïº": [
            "Ïù¥ ÍµêÏàòÎãòÏùò Ï£ºÏöî Ïó∞Íµ¨ Î∂ÑÏïºÎäî Î¨¥ÏóáÏù∏Í∞ÄÏöî?",
            "ÏµúÍ∑º Ïó∞Íµ¨ ÎèôÌñ•Í≥º Î∞©Ìñ•ÏÑ±ÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî",
            "Ïù¥ Î∂ÑÏïºÏóêÏÑú Ï£ºÎ™©Î∞õÎäî Ïó∞Íµ¨ Ï£ºÏ†úÎäî Î¨¥ÏóáÏù∏Í∞ÄÏöî?",
            "Í¥ÄÎ†® ÏµúÏã† ÎÖºÎ¨∏Ïù¥ÎÇò ÌïôÌöå Î∞úÌëúÎ•º Ï∂îÏ≤úÌï¥Ï£ºÏÑ∏Ïöî"
        ],
        "üìù ÏßÄÏõêÏÑú ÏûëÏÑ±": [
            "Ïó∞Íµ¨Í≥ÑÌöçÏÑú ÏûëÏÑ± Ïãú Ï£ºÏùòÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî?",
            "Ïù¥ ÍµêÏàòÎãòÏù¥ ÏÑ†Ìò∏ÌïòÎäî Ïó∞Íµ¨ Î∞©Î≤ïÎ°†Ïù¥ ÏûàÎÇòÏöî?",
            "SOP(Î™©Ï†ÅÏßÑÏà†ÏÑú)Ïóê Ìè¨Ìï®Ìï¥Ïïº Ìï† ÌïµÏã¨ ÎÇ¥Ïö©ÏùÄ?",
            "ÏßÄÏõêÏÑúÏóêÏÑú Í∞ïÏ°∞Ìï¥Ïïº Ìï† Í≤ΩÌóòÏù¥ÎÇò Ïó≠ÎüâÏùÄ?"
        ],
        "üéì ÎåÄÌïôÏõê ÏÉùÌôú": [
            "Ïù¥ Ïó∞Íµ¨Ïã§Ïùò Î∂ÑÏúÑÍ∏∞ÏôÄ Î¨∏ÌôîÎäî Ïñ¥Îñ§Í∞ÄÏöî?",
            "ÎåÄÌïôÏõêÏÉùÎì§ÏùÄ Ï£ºÎ°ú Ïñ¥Îñ§ ÌîÑÎ°úÏ†ùÌä∏Î•º ÌïòÎÇòÏöî?",
            "Ï°∏ÏóÖ ÏöîÍ±¥Í≥º ÎÖºÎ¨∏ Î∞úÌëú Í≥ºÏ†ïÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî",
            "Ïó∞Íµ¨Ïã§ÏóêÏÑú Ï†úÍ≥µÌïòÎäî ÍµêÏú°Ïù¥ÎÇò Ìä∏Î†àÏù¥ÎãùÏùÄ?"
        ],
        "üíº ÏßÑÎ°ú & Ïª§Î¶¨Ïñ¥": [
            "Ïù¥ Ï†ÑÍ≥µÏúºÎ°ú Ï°∏ÏóÖ ÌõÑ ÏßÑÎ°úÎäî Ïñ¥ÎñªÍ≤å ÎêòÎÇòÏöî?",
            "ÏóÖÍ≥ÑÏóêÏÑú ÏöîÍµ¨ÌïòÎäî ÌïµÏã¨ Ïó≠ÎüâÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî?",
            "Í¥ÄÎ†® ÏûêÍ≤©Ï¶ùÏù¥ÎÇò Ï∂îÍ∞Ä ÍµêÏú°Ïù¥ ÌïÑÏöîÌïúÍ∞ÄÏöî?",
            "ÎÑ§Ìä∏ÏõåÌÇπÏù¥ÎÇò ÌïôÌöå Ï∞∏Ïó¨ Ï°∞Ïñ∏ÏùÑ Ìï¥Ï£ºÏÑ∏Ïöî"
        ],
        "üìö Ï§ÄÎπÑ ÏÇ¨Ìï≠": [
            "ÏßÄÏõê Ï†ÑÏóê ÎØ∏Î¶¨ Í≥µÎ∂ÄÌï¥Ïïº Ìï† ÎÇ¥Ïö©ÏùÄ?",
            "Ï∂îÏ≤ú ÎèÑÏÑúÎÇò ÎÖºÎ¨∏Ïù¥ ÏûàÎã§Î©¥ ÏïåÎ†§Ï£ºÏÑ∏Ïöî",
            "ÌïÑÏöîÌïú ÏÑ†ÏàòÍ≥ºÎ™©Ïù¥ÎÇò Î∞∞Í≤ΩÏßÄÏãùÏùÄ?",
            "Ïó∞Íµ¨ ÎèÑÍµ¨ÎÇò ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏÇ¨Ïö©Î≤ïÏùÑ Î∞∞ÏõåÏïº ÌïòÎÇòÏöî?"
        ]
    }

def chat_with_gpt(api_key, professor_data, user_message, conversation_history=[]):
    """ChatGPT APIÎ•º ÏÇ¨Ïö©Ìïú ÎåÄÌôî Ìï®Ïàò"""
    try:
        client = openai.OpenAI(api_key=api_key)
        
        # ÏãúÏä§ÌÖú ÌîÑÎ°¨ÌîÑÌä∏ ÏÑ§Ï†ï
        system_prompt = get_professor_prompt_template(professor_data)
        
        # ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨ Íµ¨ÏÑ±
        messages = [{"role": "system", "content": system_prompt}]
        
        # Ïù¥Ï†Ñ ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨ Ï∂îÍ∞Ä
        for entry in conversation_history:
            messages.append({"role": "user", "content": entry["user"]})
            messages.append({"role": "assistant", "content": entry["assistant"]})
        
        # ÌòÑÏû¨ ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄ Ï∂îÍ∞Ä
        messages.append({"role": "user", "content": user_message})
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=1500,
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"‚ùå ChatGPT ÏùëÎãµ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}"

def search_psychology_videos(api_key, search_query="ÏûÑÏÉÅÏã¨Î¶¨Ìïô", category="ÍµêÏú°"):
    """ÏûÑÏÉÅÏã¨Î¶¨Ìïô Í¥ÄÎ†® ÎèôÏòÅÏÉÅÏùÑ Í≤ÄÏÉâÌïòÎäî Ìï®Ïàò"""
    try:
        if not api_key:
            st.error("YouTube API ÌÇ§Î•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
            return []
        
        url = "https://www.googleapis.com/youtube/v3/search"
        params = {
            'part': 'snippet',
            'q': search_query,
            'type': 'video',
            'order': 'relevance',
            'maxResults': 30,
            'regionCode': 'KR',
            'relevanceLanguage': 'ko',
            'key': api_key
        }
        
        response = requests.get(url, params=params)
        response.raise_for_status()
        
        search_data = response.json()
        video_ids = [item['id']['videoId'] for item in search_data.get('items', [])]
        
        if not video_ids:
            return []
        
        # ÎπÑÎîîÏò§ ÏÉÅÏÑ∏ Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Í∏∞
        details_url = "https://www.googleapis.com/youtube/v3/videos"
        details_params = {
            'part': 'snippet,statistics,contentDetails',
            'id': ','.join(video_ids),
            'key': api_key
        }
        
        details_response = requests.get(details_url, params=details_params)
        details_response.raise_for_status()
        
        details_data = details_response.json()
        return details_data.get('items', [])
        
    except requests.exceptions.RequestException as e:
        st.error(f"API ÏöîÏ≤≠ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}")
        return []
    except Exception as e:
        st.error(f"ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}")
        return []

def format_view_count(view_count):
    """Ï°∞ÌöåÏàòÎ•º ÏùΩÍ∏∞ Ïâ¨Ïö¥ ÌòïÌÉúÎ°ú Ìè¨Îß∑ÌåÖ"""
    try:
        count = int(view_count)
        if count >= 100000000:  # 1Ïñµ Ïù¥ÏÉÅ
            return f"{count//100000000}Ïñµ{(count%100000000)//10000:,}Îßå"
        elif count >= 10000:  # 1Îßå Ïù¥ÏÉÅ
            return f"{count//10000:,}Îßå"
        else:
            return f"{count:,}"
    except:
        return view_count

def get_psychology_categories():
    """ÏûÑÏÉÅÏã¨Î¶¨Ìïô Í¥ÄÎ†® Ïπ¥ÌÖåÍ≥†Î¶¨ Î™©Î°ù"""
    return {
        "ÏûÑÏÉÅÏã¨Î¶¨Ìïô Í∏∞Ï¥à": "ÏûÑÏÉÅÏã¨Î¶¨Ìïô Í∏∞Ï¥à Ïù¥Î°†",
        "Ïã¨Î¶¨ÏπòÎ£å Í∏∞Î≤ï": "Ïã¨Î¶¨ÏπòÎ£å Í∏∞Î≤ï CBT Ïù∏ÏßÄÌñâÎèôÏπòÎ£å",
        "Ï†ïÏã†Í±¥Í∞ï": "Ï†ïÏã†Í±¥Í∞ï Ïö∞Ïö∏Ï¶ù Î∂àÏïàÏû•Ïï†",
        "Ïã¨Î¶¨ÌèâÍ∞Ä": "Ïã¨Î¶¨ÌèâÍ∞Ä Ïã¨Î¶¨Í≤ÄÏÇ¨",
        "Î∞úÎã¨Ïã¨Î¶¨Ìïô": "Î∞úÎã¨Ïã¨Î¶¨Ìïô ÏïÑÎèôÏã¨Î¶¨",
        "Ìä∏ÎùºÏö∞Îßà ÏπòÎ£å": "Ìä∏ÎùºÏö∞Îßà ÏπòÎ£å EMDR",
        "Í∞ÄÏ°±ÏπòÎ£å": "Í∞ÄÏ°±ÏπòÎ£å Î∂ÄÎ∂ÄÏÉÅÎã¥",
        "Ï§ëÎèÖÏπòÎ£å": "Ï§ëÎèÖÏπòÎ£å ÏïåÏΩîÏò¨ ÎèÑÎ∞ï",
        "ÏßëÎã®ÏπòÎ£å": "ÏßëÎã®ÏπòÎ£å Í∑∏Î£πÏÉÅÎã¥",
        "Ïã¨Î¶¨Ìïô Ïó∞Íµ¨": "Ïã¨Î¶¨Ìïô Ïó∞Íµ¨Î∞©Î≤ïÎ°†"
    }

def get_apa_doctoral_categories():
    """APA Î∞ïÏÇ¨Í≥ºÏ†ï Ï§ÄÎπÑÏö© Í≥†Í∏â Ï†ÑÎ¨∏ Ïπ¥ÌÖåÍ≥†Î¶¨"""
    return {
        "Ïã†Í≤ΩÏã¨Î¶¨Ìïô": "neuropsychology cognitive assessment brain injury dementia",
        "ÏûÑÏÉÅÏ†ïÏã†Î≥ëÎ¶¨Ìïô": "psychopathology DSM-5 diagnostic criteria differential diagnosis",
        "Ïã¨Î¶¨ÏπòÎ£å Ïù¥Î°† ÌÜµÌï©": "psychotherapy integration theoretical orientation case conceptualization",
        "Ïã¨Î¶¨ÌèâÍ∞Ä Ï†ÑÎ¨∏": "psychological assessment WAIS MMPI projective testing",
        "Ïó∞Íµ¨ Î∞©Î≤ïÎ°†": "research methodology statistics dissertation IRB ethics",
        "Îã§Î¨∏Ìôî ÏûÑÏÉÅÏã¨Î¶¨Ìïô": "multicultural psychology diversity cultural competence",
        "Í±¥Í∞ïÏã¨Î¶¨Ìïô": "health psychology medical psychology chronic illness",
        "Î≤ïÏ†ïÏã¨Î¶¨Ìïô": "forensic psychology competency evaluation expert witness",
        "ÏûÑÏÉÅÏàòÌçºÎπÑÏ†Ñ": "clinical supervision training doctoral internship",
        "Ï†ÑÎ¨∏Ïú§Î¶¨": "professional ethics APA ethics code boundaries dual relationships",
        "Ï†ïÏã†ÏïΩÎ¶¨Ìïô": "psychopharmacology medication interaction psychology",
        "ÏÑ±Ïù∏ Ïã¨Î¶¨ÏπòÎ£å": "adult psychotherapy evidence-based treatment protocols",
        "ÏïÑÎèôÏ≤≠ÏÜåÎÖÑ ÏûÑÏÉÅ": "child adolescent psychology developmental psychopathology",
        "Ïª§Ìîå Í∞ÄÏ°±ÏπòÎ£å": "couples therapy family systems structural therapy",
        "DBT & CBT Í≥†Í∏â": "dialectical behavior therapy cognitive behavioral therapy skills",
        "Ìä∏ÎùºÏö∞Îßà Ï†ÑÎ¨∏ÏπòÎ£å": "trauma therapy PTSD complex trauma EMDR",
        "ÏÑ±Í≤©Ïû•Ïï† ÏπòÎ£å": "personality disorders borderline narcissistic treatment",
        "Ï§ëÎèÖ Ï†ÑÎ¨∏ÏπòÎ£å": "addiction psychology substance abuse recovery treatment",
        "ÏßëÎã® Ïã¨Î¶¨ÏπòÎ£å": "group therapy process group dynamics therapeutic factors",
        "Ï†ïÏã†Î∂ÑÏÑù Ïù¥Î°†": "psychoanalytic theory object relations attachment theory"
    }

def search_professor_videos(api_key, professor_name, research_keywords):
    """ÌäπÏ†ï ÍµêÏàòÏùò Ïó∞Íµ¨ Î∂ÑÏïºÏôÄ Í¥ÄÎ†®Îêú ÎèôÏòÅÏÉÅÏùÑ Í≤ÄÏÉâÌïòÎäî Ìï®Ïàò"""
    search_query = f"{professor_name} {research_keywords} psychology lecture research"
    return search_psychology_videos(api_key, search_query)

def display_professor_info(professor_data, openai_api_key=None):
    """ÍµêÏàò Ï†ïÎ≥¥Î•º ÌëúÏãúÌïòÎäî Ìï®Ïàò"""
    prof = professor_data["professor"]
    
    st.markdown(f"### üë®‚Äçüè´ {prof['name']}")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown(f"**üèõÔ∏è ÏÜåÏÜç:** {professor_data['university']}")
        st.markdown(f"**üìç ÏúÑÏπò:** {professor_data['location']}")
        st.markdown(f"**üéì ÌîÑÎ°úÍ∑∏Îû®:** {professor_data['program_type']}")
        
        if prof.get('lab'):
            st.markdown(f"**üî¨ Ïó∞Íµ¨Ïã§:** {prof['lab']}")
        
        st.markdown("**üîç Ïó∞Íµ¨ Î∂ÑÏïº:**")
        for area in prof['research_areas']:
            st.markdown(f"- {area}")
    
    with col2:
        if prof.get('email'):
            st.markdown(f"**üìß Ïù¥Î©îÏùº:** {prof['email']}")
    
    return prof

def display_chatgpt_section(professor_data, openai_api_key, unique_key):
    """ÍµêÏàòÎãòÎ≥Ñ ChatGPT ÏÑπÏÖò ÌëúÏãú"""
    if not openai_api_key:
        st.info("ü§ñ ChatGPT ÏÉÅÎã¥ÏùÑ ÏúÑÌï¥ ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú OpenAI API ÌÇ§Î•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
        return
    
    prof = professor_data["professor"]
    st.markdown(f"### ü§ñ {prof['name']} ÍµêÏàòÎãò Ïó∞Íµ¨Ïã§ ÏßÄÏõê ÏÉÅÎã¥")
    
    # ÏßàÎ¨∏ Í≤¨Î≥∏ ÏÑπÏÖò
    with st.expander("üí° Ï∂îÏ≤ú ÏßàÎ¨∏ Í≤¨Î≥∏", expanded=False):
        question_templates = get_question_templates()
        
        for category, questions in question_templates.items():
            st.markdown(f"**{category}**")
            for i, question in enumerate(questions):
                if st.button(f"‚ùì {question}", key=f"{unique_key}_template_{category}_{i}"):
                    st.session_state[f'chat_input_{unique_key}'] = question
            st.markdown("")
    
    # ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨ Ï¥àÍ∏∞Ìôî
    chat_history_key = f'chat_history_{unique_key}'
    if chat_history_key not in st.session_state:
        st.session_state[chat_history_key] = []
    
    # ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨ ÌëúÏãú
    if st.session_state[chat_history_key]:
        st.markdown("#### üí¨ ÎåÄÌôî Í∏∞Î°ù")
        for entry in st.session_state[chat_history_key]:
            with st.container():
                st.markdown(f"**üë§ ÏßàÎ¨∏:** {entry['user']}")
                st.markdown(f"**ü§ñ ÎãµÎ≥Ä:** {entry['assistant']}")
                st.markdown("---")
    
    # ÏÉà ÏßàÎ¨∏ ÏûÖÎ†•
    user_input_key = f'chat_input_{unique_key}'
    if user_input_key not in st.session_state:
        st.session_state[user_input_key] = ""
    
    user_message = st.text_area(
        "ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî:",
        value=st.session_state.get(user_input_key, ""),
        placeholder="Ïòà: Ïù¥ ÍµêÏàòÎãòÏùò Ïó∞Íµ¨ Î∂ÑÏïºÏóê ÎåÄÌï¥ ÏûêÏÑ∏Ìûà ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî.",
        height=100,
        key=f"text_area_{unique_key}"
    )
    
    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("üí¨ ÏßàÎ¨∏ÌïòÍ∏∞", key=f"ask_{unique_key}"):
            if user_message.strip():
                with st.spinner("ü§ñ ChatGPTÍ∞Ä ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ± Ï§ëÏûÖÎãàÎã§..."):
                    response = chat_with_gpt(
                        openai_api_key, 
                        professor_data, 
                        user_message, 
                        st.session_state[chat_history_key]
                    )
                    
                    # ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨Ïóê Ï∂îÍ∞Ä
                    st.session_state[chat_history_key].append({
                        "user": user_message,
                        "assistant": response
                    })
                    
                    # ÏûÖÎ†•Ï∞Ω Ï¥àÍ∏∞Ìôî
                    st.session_state[user_input_key] = ""
                    st.rerun()
            else:
                st.warning("ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
    
    with col2:
        if st.button("üóëÔ∏è ÎåÄÌôî Í∏∞Î°ù ÏÇ≠Ï†ú", key=f"clear_{unique_key}"):
            st.session_state[chat_history_key] = []
            st.success("ÎåÄÌôî Í∏∞Î°ùÏù¥ ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§.")
            st.rerun()

def main():
    st.title("üß† ÏûÑÏÉÅÏã¨Î¶¨Ìïô ÎèôÏòÅÏÉÅ & ÍµêÏàòÏßÑ Ï∂îÏ≤ú")
    st.markdown("**APA Ïù∏Ï¶ù 186Í∞ú ÎåÄÌïôÏùò ÏûÑÏÉÅÏã¨Î¶¨Ìïô ÍµêÏàòÏßÑÍ≥º Í¥ÄÎ†® ÎèôÏòÅÏÉÅÏùÑ Ï∞æÏïÑÎìúÎ¶ΩÎãàÎã§**")
    
    # Ï†ÑÏó≠ API ÌÇ§ ÏÑ§Ï†ï (ÏÇ¨Ïù¥ÎìúÎ∞îÏóê Ìïú Î≤àÎßå ÌëúÏãú)
    with st.sidebar:
        st.header("üéØ API ÏÑ§Ï†ï")
        
        # YouTube API ÌÇ§
        youtube_api_key = st.text_input(
            "YouTube API ÌÇ§:",
            type="password",
            placeholder="AIzaSy...",
            help="Google Cloud ConsoleÏóêÏÑú YouTube Data API v3 ÌÇ§Î•º Î∞úÍ∏âÎ∞õÏúºÏÑ∏Ïöî"
        )
        
        # OpenAI API ÌÇ§
        openai_api_key = st.text_input(
            "OpenAI API ÌÇ§:",
            type="password", 
            placeholder="sk-...",
            help="OpenAIÏóêÏÑú Î∞úÍ∏âÎ∞õÏùÄ API ÌÇ§Î•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî"
        )
        
        # .env ÌååÏùºÏóêÏÑú API ÌÇ§ Í∞ÄÏ†∏Ïò§Í∏∞ (Î∞±ÏóÖ)
        if not youtube_api_key:
            youtube_api_key = os.getenv('YOUTUBE_API_KEY')
        if not openai_api_key:
            openai_api_key = os.getenv('OPENAI_API_KEY')
        
        # API ÌÇ§ ÏÉÅÌÉú ÌëúÏãú
        st.markdown("---")
        st.markdown("**üìä API ÏÉÅÌÉú:**")
        st.write("üé¨ YouTube:", "‚úÖ Ïó∞Í≤∞Îê®" if youtube_api_key else "‚ùå ÎØ∏ÏÑ§Ï†ï")
        st.write("ü§ñ ChatGPT:", "‚úÖ Ïó∞Í≤∞Îê®" if openai_api_key else "‚ùå ÎØ∏ÏÑ§Ï†ï")
    
    # ÌÉ≠ ÏÉùÏÑ±
    tab1, tab2, tab3 = st.tabs(["üé¨ ÎèôÏòÅÏÉÅ Í≤ÄÏÉâ", "üë®‚Äçüè´ ÍµêÏàòÏßÑ Í≤ÄÏÉâ", "üèõÔ∏è ÎåÄÌïôÎ≥Ñ ÍµêÏàòÏßÑ"])
    
    with tab1:
        st.markdown("### üé¨ ÏûÑÏÉÅÏã¨Î¶¨Ìïô ÎèôÏòÅÏÉÅ Í≤ÄÏÉâ")
        video_search_interface(youtube_api_key)
    
    with tab2:
        st.markdown("### üë®‚Äçüè´ APA Ïù∏Ï¶ù ÍµêÏàòÏßÑ Í≤ÄÏÉâ")
        professor_search_interface(youtube_api_key, openai_api_key)
    
    with tab3:
        st.markdown("### üèõÔ∏è ÎåÄÌïôÎ≥Ñ ÍµêÏàòÏßÑ ÌÉêÏÉâ")
        university_interface(youtube_api_key, openai_api_key)

def video_search_interface(api_key):
    """ÎèôÏòÅÏÉÅ Í≤ÄÏÉâ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§"""
    st.markdown("---")
    
    # ÎÇúÏù¥ÎèÑ Î†àÎ≤® ÏÑ†ÌÉù
    level = st.radio(
        "üéì ÌïôÏäµ Î†àÎ≤®:",
        ["üìö Í∏∞Ï¥à-Ï§ëÍ∏â", "üéì APA Î∞ïÏÇ¨Í≥ºÏ†ï"],
        help="Í∏∞Ï¥à-Ï§ëÍ∏â: ÏùºÎ∞òÏ†ÅÏù∏ ÏûÑÏÉÅÏã¨Î¶¨Ìïô ÎÇ¥Ïö©\nAPA Î∞ïÏÇ¨Í≥ºÏ†ï: Í≥†Í∏â Ï†ÑÎ¨∏ ÏßÄÏãù Î∞è ÏòÅÏñ¥ ÏΩòÌÖêÏ∏†"
    )
    
    # Î†àÎ≤®Ïóê Îî∞Î•∏ Ïπ¥ÌÖåÍ≥†Î¶¨ ÏÑ†ÌÉù
    if level == "üìö Í∏∞Ï¥à-Ï§ëÍ∏â":
        categories = get_psychology_categories()
        st.info("üìñ Í∏∞Ï¥àÎ∂ÄÌÑ∞ Ï§ëÍ∏âÍπåÏßÄÏùò ÏûÑÏÉÅÏã¨Î¶¨Ìïô ÎÇ¥Ïö©")
    else:
        categories = get_apa_doctoral_categories()
        st.warning("üéì APA Î∞ïÏÇ¨Í≥ºÏ†ï ÏàòÏ§ÄÏùò Ï†ÑÎ¨∏ ÎÇ¥Ïö© (Ï£ºÎ°ú ÏòÅÏñ¥)")
    
    selected_category = st.selectbox(
        "Ï†ÑÎ¨∏ Î∂ÑÏïº:",
        options=list(categories.keys()),
        index=0
    )
    
    # Ïª§Ïä§ÌÖÄ Í≤ÄÏÉâÏñ¥
    custom_search = st.text_input(
        "Ï∂îÍ∞Ä Í≤ÄÏÉâÏñ¥:",
        placeholder="Ïòà: Ïù∏ÏßÄÌñâÎèôÏπòÎ£å, CBT protocol",
        help="ÌäπÏ†ï Ï£ºÏ†úÎ•º Îçî ÏûêÏÑ∏Ìûà Í≤ÄÏÉâÌïòÍ≥† Ïã∂Îã§Î©¥ ÏûÖÎ†•ÌïòÏÑ∏Ïöî"
    )
    
    # Ïñ∏Ïñ¥ ÏÑ§Ï†ï (APA Î†àÎ≤®Ïùº ÎïåÎßå)
    if level == "üéì APA Î∞ïÏÇ¨Í≥ºÏ†ï":
        language = st.selectbox(
            "Ïñ∏Ïñ¥ Ïö∞ÏÑ†ÏàúÏúÑ:",
            ["ÏòÅÏñ¥ (English)", "ÌïúÍµ≠Ïñ¥", "ÌòºÌï©"],
            help="APA Î∞ïÏÇ¨Í≥ºÏ†ï ÎÇ¥Ïö©ÏùÄ ÏòÅÏñ¥ ÏûêÎ£åÍ∞Ä Îçî ÌíçÎ∂ÄÌï©ÎãàÎã§"
        )
    else:
        language = "ÌïúÍµ≠Ïñ¥"
    
    # Í≤ÄÏÉâ Î≤ÑÌäº
    search_button = st.button("üîç ÎèôÏòÅÏÉÅ Í≤ÄÏÉâ", use_container_width=True, disabled=not api_key)
    
    # Í≤ÄÏÉâ ÏøºÎ¶¨ Íµ¨ÏÑ±
    search_query = categories[selected_category]
    if custom_search:
        search_query += f" {custom_search}"
    
    # Ïñ∏Ïñ¥Î≥Ñ Í≤ÄÏÉâÏñ¥ Ï°∞Ï†ï
    if level == "üéì APA Î∞ïÏÇ¨Í≥ºÏ†ï":
        if language == "ÏòÅÏñ¥ (English)":
            search_query = search_query
        elif language == "ÌïúÍµ≠Ïñ¥":
            search_query += " ÌïúÍµ≠Ïñ¥ Î≤àÏó≠ korean"
    
    if (search_button or 'videos' not in st.session_state) and api_key:
        with st.spinner(f'\'{selected_category}\' Í¥ÄÎ†® ÎèôÏòÅÏÉÅÏùÑ Í≤ÄÏÉâ Ï§ë...'):
            st.session_state.videos = search_psychology_videos(api_key, search_query)
            st.session_state.last_search = {
                'category': selected_category,
                'level': level,
                'query': search_query,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    videos = st.session_state.get('videos', [])
    
    if not api_key:
        st.info("üëà ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú YouTube API ÌÇ§Î•º ÏûÖÎ†•ÌïòÍ±∞ÎÇò .env ÌååÏùºÏóê ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî.")
        return
    
    if not videos and api_key:
        st.warning("Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§. Îã§Î•∏ Ïπ¥ÌÖåÍ≥†Î¶¨Î•º ÏãúÎèÑÌï¥Î≥¥Í±∞ÎÇò Í≤ÄÏÉâÏñ¥Î•º ÏàòÏ†ïÌï¥Ï£ºÏÑ∏Ïöî.")
        return
    
    # Í≤ÄÏÉâ Í≤∞Í≥º ÌëúÏãú
    display_video_results(videos)

def professor_search_interface(youtube_api_key, openai_api_key):
    """ÍµêÏàòÏßÑ Í≤ÄÏÉâ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§"""
    st.markdown("---")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("#### üîç Ïó∞Íµ¨ Î∂ÑÏïºÎ°ú Í≤ÄÏÉâ")
        research_keyword = st.text_input(
            "Ïó∞Íµ¨ ÌÇ§ÏõåÎìú:",
            placeholder="Ïòà: depression, CBT, PTSD, anxiety",
            help="Í¥ÄÏã¨ ÏûàÎäî Ïó∞Íµ¨ Î∂ÑÏïºÎÇò ÌÇ§ÏõåÎìúÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî"
        )
        
        if st.button("üîç ÍµêÏàò Í≤ÄÏÉâ", disabled=not research_keyword):
            professors = search_professors_by_keyword(research_keyword)
            st.session_state.searched_professors = professors
            st.session_state.search_keyword = research_keyword
    
    with col2:
        st.markdown("#### üìä ÌÜµÍ≥Ñ Ï†ïÎ≥¥")
        total_universities = len(APA_PROFESSORS_DATABASE)
        total_professors = sum(len(info["professors"]) for info in APA_PROFESSORS_DATABASE.values())
        
        st.metric("APA Ïù∏Ï¶ù ÎåÄÌïô", f"{total_universities}Í∞ú")
        st.metric("Îì±Î°ùÎêú ÍµêÏàò", f"{total_professors}Î™Ö")
        
        # Ï£ºÏöî Ïó∞Íµ¨ Î∂ÑÏïº
        st.markdown("**Ï£ºÏöî Ïó∞Íµ¨ Î∂ÑÏïº:**")
        areas = get_research_areas()
        for area in areas[:8]:
            st.markdown(f"‚Ä¢ {area}")
    
    # Í≤ÄÏÉâ Í≤∞Í≥º ÌëúÏãú
    if hasattr(st.session_state, 'searched_professors') and st.session_state.searched_professors:
        st.markdown(f"### üéØ '{st.session_state.search_keyword}' Í≤ÄÏÉâ Í≤∞Í≥º ({len(st.session_state.searched_professors)}Î™Ö)")
        
        for i, prof_data in enumerate(st.session_state.searched_professors):
            with st.expander(f"üë®‚Äçüè´ {prof_data['professor']['name']} - {prof_data['university']}"):
                prof = display_professor_info(prof_data, openai_api_key)
                
                st.markdown("---")
                
                # ChatGPT ÏÉÅÎã¥ ÏÑπÏÖò
                display_chatgpt_section(prof_data, openai_api_key, f"search_{i}")
                
                st.markdown("---")
                
                # Í¥ÄÎ†® ÎèôÏòÅÏÉÅ Í≤ÄÏÉâ Î≤ÑÌäº
                if youtube_api_key:
                    if st.button(f"üé¨ {prof['name']} Í¥ÄÎ†® ÎèôÏòÅÏÉÅ Í≤ÄÏÉâ", key=f"video_search_{i}"):
                        with st.spinner(f"{prof['name']} Í¥ÄÎ†® ÎèôÏòÅÏÉÅ Í≤ÄÏÉâ Ï§ë..."):
                            videos = search_professor_videos(youtube_api_key, prof['name'], prof['research_keywords'])
                            st.session_state[f'prof_videos_{i}'] = videos
                    
                    # ÎèôÏòÅÏÉÅ Í≤∞Í≥º ÌëúÏãú
                    if f'prof_videos_{i}' in st.session_state:
                        videos = st.session_state[f'prof_videos_{i}']
                        if videos:
                            st.markdown(f"#### üé¨ {prof['name']} Í¥ÄÎ†® ÎèôÏòÅÏÉÅ ({len(videos)}Í∞ú)")
                            display_video_results(videos, compact=True)
                        else:
                            st.info("Í¥ÄÎ†® ÎèôÏòÅÏÉÅÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")

def university_interface(youtube_api_key, openai_api_key):
    """ÎåÄÌïôÎ≥Ñ ÍµêÏàòÏßÑ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§"""
    st.markdown("---")
    
    universities = get_universities()
    selected_university = st.selectbox(
        "üèõÔ∏è ÎåÄÌïô ÏÑ†ÌÉù:",
        options=universities,
        index=0
    )
    
    if selected_university:
        university_info = APA_PROFESSORS_DATABASE[selected_university]
        professors = university_info["professors"]
        
        st.markdown(f"### üèõÔ∏è {selected_university}")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown(f"**üìç ÏúÑÏπò:** {university_info['location']}")
            st.markdown(f"**üéì ÌîÑÎ°úÍ∑∏Îû®:** {university_info['program_type']}")
        with col2:
            st.metric("ÍµêÏàòÏßÑ Ïàò", f"{len(professors)}Î™Ö")
        
        st.markdown("---")
        
        # ÍµêÏàòÏßÑ Î™©Î°ù
        for i, prof in enumerate(professors):
            with st.expander(f"üë®‚Äçüè´ {prof['name']} - {', '.join(prof['research_areas'][:3])}"):
                prof_data = {
                    "professor": prof,
                    "university": selected_university,
                    "location": university_info["location"],
                    "program_type": university_info["program_type"]
                }
                
                display_professor_info(prof_data, openai_api_key)
                
                st.markdown("---")
                
                # ChatGPT ÏÉÅÎã¥ ÏÑπÏÖò
                display_chatgpt_section(prof_data, openai_api_key, f"univ_{i}")
                
                st.markdown("---")
                
                # Í¥ÄÎ†® ÎèôÏòÅÏÉÅ Í≤ÄÏÉâ
                if youtube_api_key:
                    if st.button(f"üé¨ {prof['name']} Í¥ÄÎ†® ÎèôÏòÅÏÉÅ Í≤ÄÏÉâ", key=f"univ_video_{i}"):
                        with st.spinner(f"{prof['name']} Í¥ÄÎ†® ÎèôÏòÅÏÉÅ Í≤ÄÏÉâ Ï§ë..."):
                            videos = search_professor_videos(youtube_api_key, prof['name'], prof['research_keywords'])
                            st.session_state[f'univ_prof_videos_{i}'] = videos
                    
                    # ÎèôÏòÅÏÉÅ Í≤∞Í≥º ÌëúÏãú
                    if f'univ_prof_videos_{i}' in st.session_state:
                        videos = st.session_state[f'univ_prof_videos_{i}']
                        if videos:
                            st.markdown(f"#### üé¨ {prof['name']} Í¥ÄÎ†® ÎèôÏòÅÏÉÅ ({len(videos)}Í∞ú)")
                            display_video_results(videos, compact=True)
                        else:
                            st.info("Í¥ÄÎ†® ÎèôÏòÅÏÉÅÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")

def display_video_results(videos, compact=False):
    """ÎèôÏòÅÏÉÅ Í≤∞Í≥ºÎ•º ÌëúÏãúÌïòÎäî Ìï®Ïàò"""
    if not videos:
        return
    
    max_videos = 5 if compact else len(videos)
    
    for video in videos[:max_videos]:
        snippet = video.get('snippet', {})
        statistics = video.get('statistics', {})
        
        video_id = video.get('id', '')
        title = snippet.get('title', 'Ï†úÎ™© ÏóÜÏùå')
        channel_name = snippet.get('channelTitle', 'Ï±ÑÎÑêÎ™Ö ÏóÜÏùå')
        thumbnail_url = snippet.get('thumbnails', {}).get('medium', {}).get('url', '')
        view_count = statistics.get('viewCount', '0')
        published_at = snippet.get('publishedAt', '')
        description = snippet.get('description', '')[:100] + '...' if len(snippet.get('description', '')) > 100 else snippet.get('description', '')
        
        video_url = f"https://www.youtube.com/watch?v={video_id}"
        
        try:
            pub_date = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
            formatted_date = pub_date.strftime('%Y-%m-%d')
        except:
            formatted_date = 'ÎÇ†Ïßú ÏóÜÏùå'
        
        col1, col2, col3, col4, col5 = st.columns([0.8, 3.5, 1.2, 1, 1])
        
        with col1:
            if thumbnail_url:
                st.image(thumbnail_url, width=100)
        
        with col2:
            st.markdown(f"**{title[:80]}{'...' if len(title) > 80 else ''}**")
            if description and not compact:
                st.caption(f"{description[:60]}{'...' if len(description) > 60 else ''}")
        
        with col3:
            st.write(f"**{channel_name[:15]}{'...' if len(channel_name) > 15 else ''}**")
            st.caption(f"{formatted_date}")
        
        with col4:
            st.write(f"**{format_view_count(view_count)}Ìöå**")
        
        with col5:
            st.markdown(f"[‚ñ∂Ô∏è Î≥¥Í∏∞]({video_url})")

if __name__ == "__main__":
    main()